{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"},{"sourceId":7596123,"sourceType":"datasetVersion","datasetId":4421492},{"sourceId":7739593,"sourceType":"datasetVersion","datasetId":4523606},{"sourceId":7832262,"sourceType":"datasetVersion","datasetId":4590351}],"dockerImageVersionId":30665,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import transformers\nimport json\nimport numpy as np\nimport tensorflow as tf\nnp.object = object\nimport torch\n\nfrom datasets import Dataset\nprint(transformers.__version__)","metadata":{"id":"kfJNHJMVhaVZ","outputId":"5e20f871-f2e9-4a38-f898-1c69e8f9ff12","execution":{"iopub.status.busy":"2024-03-13T09:44:50.946401Z","iopub.execute_input":"2024-03-13T09:44:50.946799Z","iopub.status.idle":"2024-03-13T09:45:08.863528Z","shell.execute_reply.started":"2024-03-13T09:44:50.946766Z","shell.execute_reply":"2024-03-13T09:45:08.862599Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-13 09:44:58.963930: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-13 09:44:58.964023: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-13 09:44:59.132907: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"4.38.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely.","metadata":{"id":"L6dhLgWAhaVc"}},{"cell_type":"markdown","source":"## Import the trained model (model, tokenizer and data collator)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification\nmodel = AutoModelForTokenClassification.from_pretrained(\"/kaggle/input/debertav2-512\")\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/debertav2-512')\ndata_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of = 16)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:08.865393Z","iopub.execute_input":"2024-03-13T09:45:08.866116Z","iopub.status.idle":"2024-03-13T09:45:22.605674Z","shell.execute_reply.started":"2024-03-13T09:45:08.866079Z","shell.execute_reply":"2024-03-13T09:45:22.604871Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Import test dataset","metadata":{}},{"cell_type":"code","source":"data_test = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:22.606864Z","iopub.execute_input":"2024-03-13T09:45:22.607406Z","iopub.status.idle":"2024-03-13T09:45:25.119457Z","shell.execute_reply.started":"2024-03-13T09:45:22.607380Z","shell.execute_reply":"2024-03-13T09:45:25.118498Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ds_original = Dataset.from_dict({\n    \"full_text\": [x[\"full_text\"] for x in data_test],\n    \"document\": [x[\"document\"] for x in data_test],\n    \"tokens\": [x[\"tokens\"] for x in data_test],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data_test],\n})\nds_original_w_labels = Dataset.from_dict({ \n    \"full_text\": [x[\"full_text\"] for x in data_test],\n    \"document\": [x[\"document\"] for x in data_test],\n    \"tokens\": [x[\"tokens\"] for x in data_test],\n    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data_test],\n    \"provided_labels\": [x[\"labels\"] for x in data_test],\n})","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:25.121846Z","iopub.execute_input":"2024-03-13T09:45:25.122157Z","iopub.status.idle":"2024-03-13T09:45:28.037327Z","shell.execute_reply.started":"2024-03-13T09:45:25.122132Z","shell.execute_reply":"2024-03-13T09:45:28.036543Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_validtest = ds_original.train_test_split(test_size=0.2, seed = 42)\nds_original = train_validtest['test']\ntrain_validtest_w_labels = ds_original_w_labels.train_test_split(test_size=0.2, seed = 42)\nds_original_w_labels = train_validtest_w_labels['test']","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:28.038574Z","iopub.execute_input":"2024-03-13T09:45:28.039020Z","iopub.status.idle":"2024-03-13T09:45:28.067706Z","shell.execute_reply.started":"2024-03-13T09:45:28.038986Z","shell.execute_reply":"2024-03-13T09:45:28.067038Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Define the function to tokenize the dataset:\n### - The text is reconstructed from the given tokens to ensure that labels correspond to the exact token (this is not strictly necessary but is to avoid any discrepancy).\n### - token_map contains a map character <-> word_index, where word_index is a number corresponding to its position in the document (first word in the document -> 0)\n### - The offset mapping is returned too","metadata":{}},{"cell_type":"code","source":"max_model_input_length = 512","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:28.068973Z","iopub.execute_input":"2024-03-13T09:45:28.069314Z","iopub.status.idle":"2024-03-13T09:45:28.073304Z","shell.execute_reply.started":"2024-03-13T09:45:28.069283Z","shell.execute_reply":"2024-03-13T09:45:28.072388Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def tokenize(example, tokenizer):\n\n    text = []\n    token_map = []\n    \n    idx = 0\n    for t, ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n        \n        text.append(t)\n        \n        token_map.extend([idx]*len(t))\n        \n        if ws:\n            text.append(\" \")\n            token_map.append(-1)\n            \n        idx += 1\n        \n    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, padding = 'max_length',max_length = 512, return_overflowing_tokens = True)\n    \n    return {\n        **tokenized,\n        \"token_map\": token_map,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:28.074493Z","iopub.execute_input":"2024-03-13T09:45:28.075191Z","iopub.status.idle":"2024-03-13T09:45:28.083783Z","shell.execute_reply.started":"2024-03-13T09:45:28.075157Z","shell.execute_reply":"2024-03-13T09:45:28.082981Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize the dataset","metadata":{}},{"cell_type":"code","source":"ds_original = ds_original.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer}, num_proc = 4)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:28.084834Z","iopub.execute_input":"2024-03-13T09:45:28.085149Z","iopub.status.idle":"2024-03-13T09:45:56.407330Z","shell.execute_reply.started":"2024-03-13T09:45:28.085117Z","shell.execute_reply":"2024-03-13T09:45:56.406149Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/341 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49a163255ea04e6893dee3d80f0dbd48"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/341 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342421a967cc450baf760b1f929ad76f"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/340 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd9ad344b743475f95297001e1693ba7"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/340 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f883a74f634eb9ac30d815c7be4904"}},"metadata":{}}]},{"cell_type":"code","source":"def find_first_zero_index(lst):\n    try:\n        return lst.index(0)\n    except ValueError:\n        return -1","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:56.409064Z","iopub.execute_input":"2024-03-13T09:45:56.409923Z","iopub.status.idle":"2024-03-13T09:45:56.415665Z","shell.execute_reply.started":"2024-03-13T09:45:56.409882Z","shell.execute_reply":"2024-03-13T09:45:56.414695Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def set_last_sequence(row):\n    n_seq = len(row['input_ids'])\n    \n    token_pos_doc = np.array([[-1] * max_model_input_length] * n_seq)\n    for seq in range(n_seq):\n        token_pos_doc[seq][1:-1] = np.arange(seq*(max_model_input_length - 2), (seq+1)*(max_model_input_length - 2))\n    row['token_pos_doc'] = token_pos_doc\n    del token_pos_doc\n    \n    if n_seq >= 2:\n        zero_index = find_first_zero_index(row['input_ids'][-1])\n        if zero_index != -1:\n        # fix input_ids \n            row['input_ids'][-1][-zero_index+1:] = row['input_ids'][-1][1:zero_index]\n            row['input_ids'][-1][1:-zero_index+1] = row['input_ids'][-2][zero_index-1: -1]\n\n        # fix offset_mapping\n            row['offset_mapping'][-1][-zero_index+1:] = row['offset_mapping'][-1][1:zero_index]\n            row['offset_mapping'][-1][1:-zero_index+1] = row['offset_mapping'][-2][zero_index-1 : -1]    \n\n        # fix attention_mask\n            row['attention_mask'][-1] = [1] * max_model_input_length\n            \n        # fix token_pos_doc\n            row['token_pos_doc'][-1][-zero_index:-1] = row['token_pos_doc'][-1][:zero_index-1]\n            row['token_pos_doc'][-1][1:-zero_index+1] = row['token_pos_doc'][-2][zero_index-1 : -1]    \n    \n    return row \n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:56.430972Z","iopub.execute_input":"2024-03-13T09:45:56.431314Z","iopub.status.idle":"2024-03-13T09:45:56.442825Z","shell.execute_reply.started":"2024-03-13T09:45:56.431281Z","shell.execute_reply":"2024-03-13T09:45:56.441979Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tokenized_ds_wo_predictions = ds_original.map(set_last_sequence, num_proc = 4)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:45:56.444032Z","iopub.execute_input":"2024-03-13T09:45:56.444668Z","iopub.status.idle":"2024-03-13T09:46:07.174295Z","shell.execute_reply.started":"2024-03-13T09:45:56.444619Z","shell.execute_reply":"2024-03-13T09:46:07.173373Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/341 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"962ed8bbcedc40feaf80f9a96e71a000"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/341 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04f65b8ac41c4288aa72798b9c53a506"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/340 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"881192f62a8f42e3bdb39e3b74090424"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/340 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56b9083987164d619450188ea2bc7499"}},"metadata":{}}]},{"cell_type":"code","source":"def mean_prediction(dataframe_wo_predictions, predictions_tensor):\n    '''\n    PARAMETERS:\n        -  dataframe_wo_predictions pd.DataFrame containing one input_id for each row \n        -  predictions_tensor a (n_documents, 512, 13) tensor containing the predictions\n    \n    OUTPUT:\n        -  np.array containing the labels for a single document\n    '''\n    predictions_tensor = tf.math.softmax(predictions_tensor.predictions, axis=-1)\n    predictions_array = np.concatenate(predictions_tensor)\n    dataframe_wo_predictions['predictions'] = [row for row in predictions_array]\n    \n    predictions_df_grouped = dataframe_wo_predictions.groupby(['document', 'token_pos_doc'], group_keys = False)['predictions'].apply('mean').reset_index()\n    predictions_df_grouped = predictions_df_grouped.sort_values(by=['document', 'token_pos_doc'])\n    predictions_df_grouped = predictions_df_grouped.reset_index()\n    \n    predicted_labels = np.array([np.array(arr) for arr in predictions_df_grouped['predictions']])\n    \n    return predicted_labels[1:] # no start/end special tokens\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:46:07.175722Z","iopub.execute_input":"2024-03-13T09:46:07.176007Z","iopub.status.idle":"2024-03-13T09:46:07.183819Z","shell.execute_reply.started":"2024-03-13T09:46:07.175980Z","shell.execute_reply":"2024-03-13T09:46:07.182868Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nargs = TrainingArguments(\n    \".\", \n    per_device_eval_batch_size=16, \n    report_to=\"none\",\n)\ntrainer = Trainer(\n    model=model, \n    args=args, \n    data_collator=data_collator, \n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:46:07.184971Z","iopub.execute_input":"2024-03-13T09:46:07.185261Z","iopub.status.idle":"2024-03-13T09:46:07.896010Z","shell.execute_reply.started":"2024-03-13T09:46:07.185237Z","shell.execute_reply":"2024-03-13T09:46:07.895200Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"n_documents = len(tokenized_ds_wo_predictions)\ntokenized_ds_wo_predictions.set_format('pandas')\npreds_final = []\n\n# predict a single document each time, in this way we are saving in RAM only one document at a time\n# while the others stay in the disk\nfor i in range(n_documents):\n    # getting a single document inside RAM memory\n    df_document_i = tokenized_ds_wo_predictions[i]\n    \n    # input_ids is a list of lists so it needs to be exploded in order to make predictions\n    df_document_i = df_document_i.drop(columns = ['full_text', 'tokens', 'trailing_whitespace',\n     'offset_mapping', 'overflow_to_sample_mapping',\n       'token_map', ])\n    exploded_df = df_document_i.explode(['input_ids','attention_mask', 'token_pos_doc'])\n    \n    predictions_document_i = trainer.predict(Dataset.from_pandas(exploded_df))\n    \n    # we need to explode again in order to make each row corresponding to a single input_id (token)\n    exploded_df = exploded_df.drop(columns = ['attention_mask'])\n    exploded_df = exploded_df.explode(['input_ids', 'token_pos_doc'])\n    predictions_document_i = mean_prediction(exploded_df, predictions_document_i)\n    \n    preds_final.append(predictions_document_i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # getting a single document inside RAM memory\n# df_document_i = tokenized_ds_wo_predictions[3]\n\n# # input_ids is a list of lists so it needs to be exploded in order to make predictions\n# df_document_i = df_document_i.drop(columns = ['full_text', 'trailing_whitespace',\n#  'offset_mapping', 'overflow_to_sample_mapping', 'tokens',\n#    'token_map', ])\n# exploded_df = df_document_i.explode(['input_ids', 'attention_mask', 'token_pos_doc'])\n\n# # the dataframe is converted into a tf tensor and used to make predictions\n# tensor_document_i = (Dataset.from_pandas(exploded_df)).to_tf_dataset(\n# columns=['input_ids', 'attention_mask'],\n# batch_size=len(tokenized_ds_wo_predictions[-1]),\n# shuffle=False,\n# collate_fn=data_collator,\n# )\n# predictions_document_i = model.predict(tensor_document_i)\n\n# # we need to explode again in order to make each row corresponding to a single input_id\n# exploded_df = exploded_df.explode(['input_ids', 'token_pos_doc'])\n# dataframe_wo_predictions = exploded_df.copy() \n# predictions_tensor = predictions_document_i.copy() \n# predictions_tensor = tf.math.softmax(predictions_tensor.logits, axis=-1)\n# predictions_array = np.concatenate(predictions_tensor)\n# dataframe_wo_predictions['predictions'] = [row for row in predictions_array]\n# predictions_df_grouped = dataframe_wo_predictions.groupby(['document', 'token_pos_doc'], group_keys = False)['predictions'].apply('mean').reset_index()\n# predictions_df_grouped = predictions_df_grouped.sort_values(by=['document', 'token_pos_doc'])\n# predictions_df_grouped = predictions_df_grouped.reset_index()\n# predicted_labels = np.array([np.array(arr) for arr in predictions_df_grouped['predictions']])\n# predicted_labels = np.argmax(predicted_labels, axis = -1)\n\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:55:54.294686Z","iopub.execute_input":"2024-03-13T09:55:54.295034Z","iopub.status.idle":"2024-03-13T09:55:54.300648Z","shell.execute_reply.started":"2024-03-13T09:55:54.295006Z","shell.execute_reply":"2024-03-13T09:55:54.299679Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nconfig = json.load(open(Path('/kaggle/input/gianni/giannilbert/giannilbert') / \"config.json\"))\nid2label = config[\"id2label\"]  ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:55:54.301947Z","iopub.execute_input":"2024-03-13T09:55:54.302328Z","iopub.status.idle":"2024-03-13T09:55:54.333419Z","shell.execute_reply.started":"2024-03-13T09:55:54.302277Z","shell.execute_reply":"2024-03-13T09:55:54.332751Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def fix_offset_mapping(doc):\n    '''Remove special tokens (start/end of sequence) from offset mapping column'''\n    new_offset = []\n    for seq_offset in doc['offset_mapping']:\n        reduced_seq_offset = seq_offset[1:-1]\n        new_offset.extend(reduced_seq_offset)\n    doc['offset_mapping'] = new_offset\n    return doc\n\nds_original = ds_original.map(fix_offset_mapping)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:55:54.334515Z","iopub.execute_input":"2024-03-13T09:55:54.334863Z","iopub.status.idle":"2024-03-13T09:56:14.730647Z","shell.execute_reply.started":"2024-03-13T09:55:54.334831Z","shell.execute_reply":"2024-03-13T09:56:14.729680Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1362 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cf4dc5bf9854eefa61470baf368def0"}},"metadata":{}}]},{"cell_type":"code","source":"# Choose the aggregation strategy in case of conflict:\n#     -'first': the prediction for the first subtoken decides how the whole tkoen is classified.\n#     -'max': the prediction of the subtoken whose confidence is the highest decides how the whole tkoen is classified.\n#     -'average': the prediction for the whole is decided by performing the mean of the predictions for all the subtokens\naggregation_strategy = 'average'","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:56:14.732224Z","iopub.execute_input":"2024-03-13T09:56:14.732940Z","iopub.status.idle":"2024-03-13T09:56:14.737227Z","shell.execute_reply.started":"2024-03-13T09:56:14.732901Z","shell.execute_reply":"2024-03-13T09:56:14.736314Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def max_prob_vct(lists):\n    max_list = max(lists, key=max)\n    return max_list","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:56:14.738515Z","iopub.execute_input":"2024-03-13T09:56:14.739153Z","iopub.status.idle":"2024-03-13T09:56:14.745949Z","shell.execute_reply.started":"2024-03-13T09:56:14.739127Z","shell.execute_reply":"2024-03-13T09:56:14.745084Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"ds_original","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:56:14.746923Z","iopub.execute_input":"2024-03-13T09:56:14.747196Z","iopub.status.idle":"2024-03-13T09:56:14.757510Z","shell.execute_reply.started":"2024-03-13T09:56:14.747172Z","shell.execute_reply":"2024-03-13T09:56:14.756689Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['full_text', 'document', 'tokens', 'trailing_whitespace', 'input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping', 'token_map'],\n    num_rows: 1362\n})"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# Prepare to plunder the data for valuable triplets!\n# document, token, label, token_str = [], [], [], []\nall_documents_predictions_df = pd.DataFrame(columns = ['document', 'label', 'token','token_str', 'prob'])\ni = 0\n# Iterate over the documents (each row in the original_ds is a distinct document)\nfor p, token_map, offsets, tokens, doc in zip(preds_final, \n                                              ds_original[\"token_map\"], \n                                              ds_original[\"offset_mapping\"], \n                                              ds_original[\"tokens\"], \n                                              ds_original[\"document\"]):\n\n    document_predictions_df = pd.DataFrame(columns = ['document', 'label', 'token','token_str', 'prob'])\n\n    # Iterate through each token prediction in the document\n    for token_pred, (start_idx, end_idx) in zip(p, offsets):\n        label_pred = id2label[str(np.argmax(np.array(token_pred)))]\n\n        \n        \n        # If start and end indices sum to zero (special token), continue to the next iteration\n        # Since we have removed special tokens for beginning/end of a sequence, we should never\n        # enter this.\n        if start_idx + end_idx == 0:\n            continue\n\n        # If the token mapping at the start index is a whitespace (-1), increment start index\n        if token_map[start_idx] == -1:\n            start_idx += 1\n\n        # Ignore leading whitespace tokens (\"\\n\\n\")\n        while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n            start_idx += 1\n\n        # If start index exceeds the length of token mapping, break the loop (end of document)\n        if start_idx >= len(token_map):\n            break\n\n        token_id = token_map[start_idx]  # relative original token\n        \n        keep = token_pred[-1] < 0.99999\n        # Ignore whitespace tokens\n        if token_id != -1 and keep:\n#         if token_id != -1 :\n#             new_prediction = {'document': doc, 'label': label_pred, 'token': token_id, 'token_str': tokens[token_id], 'prob': token_pred  }\n            new_prediction = [ doc,label_pred, token_id,  tokens[token_id], token_pred]\n\n            document_predictions_df.loc[len(document_predictions_df)] = new_prediction\n#             new_prediction = {'document': doc, 'label': label_pred, 'token': token_id, 'token_str': tokens[token_id], 'prob': token_pred  }\n#             document_predictions_df = pd.concat([document_predictions_df,new_prediction], ignore_index=True)\n    \n#     grouped = document_predictions_df.groupby(['document','token','token_str'])\n#     document_predictions_df = grouped.filter(lambda x: (x['label'] != 'O').any())\n    \n    if aggregation_strategy == 'first':\n        document_predictions_df = document_predictions_df.groupby(['document','token','token_str'], group_keys = False, sort = False).first().reset_index()\n    elif aggregation_strategy == 'average':\n        document_predictions_df = document_predictions_df.groupby(['document','token','token_str', 'label'], group_keys = False, sort = False)['prob'].mean().reset_index()\n    elif aggregation_strategy == 'max':\n        document_predictions_df = document_predictions_df.groupby(['document','token','token_str'], group_keys = False, sort = False)['prob'].agg(max_prob_vct).reset_index()\n    all_documents_predictions_df = pd.concat([all_documents_predictions_df, document_predictions_df], ignore_index=True)\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:56:14.758711Z","iopub.execute_input":"2024-03-13T09:56:14.758974Z","iopub.status.idle":"2024-03-13T09:56:44.130238Z","shell.execute_reply.started":"2024-03-13T09:56:14.758951Z","shell.execute_reply":"2024-03-13T09:56:44.129339Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"all_documents_predictions_df[:60]","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:56:44.158866Z","iopub.execute_input":"2024-03-13T09:56:44.159174Z","iopub.status.idle":"2024-03-13T09:56:44.206113Z","shell.execute_reply.started":"2024-03-13T09:56:44.159147Z","shell.execute_reply":"2024-03-13T09:56:44.205131Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   document           label token  \\\n0     11301         B-EMAIL     0   \n1     11301         B-EMAIL   441   \n2      3732  B-NAME_STUDENT     0   \n3      3732  I-NAME_STUDENT     1   \n4      5470  B-NAME_STUDENT    10   \n5      5470  I-NAME_STUDENT    11   \n6     22088  B-NAME_STUDENT    17   \n7     22088  I-NAME_STUDENT    18   \n8     22088  I-NAME_STUDENT    19   \n9     12077  B-NAME_STUDENT   603   \n10    12077  B-NAME_STUDENT   605   \n11     9473  B-NAME_STUDENT     0   \n12     9473  I-NAME_STUDENT     1   \n13     9473  B-NAME_STUDENT   519   \n14     9473  I-NAME_STUDENT   520   \n15     8805  B-NAME_STUDENT     0   \n16     8805  I-NAME_STUDENT     1   \n17     8805  B-NAME_STUDENT   404   \n18     8805               O   405   \n19     8805  I-NAME_STUDENT   405   \n20    11827  B-NAME_STUDENT     0   \n21    11827  I-NAME_STUDENT     1   \n22     6296  B-NAME_STUDENT     0   \n23     6296  I-NAME_STUDENT     1   \n24     2797  B-NAME_STUDENT     7   \n25     2797  I-NAME_STUDENT     8   \n26    11049               O   138   \n27    11049  B-URL_PERSONAL   138   \n28    11049  B-URL_PERSONAL   745   \n29     9433  B-NAME_STUDENT     0   \n30     9433  I-NAME_STUDENT     1   \n31     9433  B-NAME_STUDENT    14   \n32     9433  I-NAME_STUDENT    15   \n33     4004  B-NAME_STUDENT     0   \n34     4004  I-NAME_STUDENT     1   \n35     4004  B-NAME_STUDENT   479   \n36     4004  I-NAME_STUDENT   480   \n37     3664  B-NAME_STUDENT    10   \n38     3664  I-NAME_STUDENT    11   \n39     1763  B-NAME_STUDENT    13   \n40    14695  B-NAME_STUDENT   205   \n41    14695  B-NAME_STUDENT   207   \n42     9657  B-NAME_STUDENT   241   \n43     9657  I-NAME_STUDENT   242   \n44     9657  I-NAME_STUDENT   243   \n45     9657               O   283   \n46     9657               O   888   \n47     9657               O   952   \n48     9657  B-NAME_STUDENT  1402   \n49    12426  B-NAME_STUDENT   169   \n50     4442  B-NAME_STUDENT     6   \n51     4442  I-NAME_STUDENT     7   \n52    14191  B-NAME_STUDENT  1392   \n53    14191  I-NAME_STUDENT  1393   \n54     4669  B-NAME_STUDENT    13   \n55     4669  I-NAME_STUDENT    14   \n56    10472  B-NAME_STUDENT     0   \n57    10472  I-NAME_STUDENT     1   \n58    13103  B-URL_PERSONAL    63   \n59    13103  B-URL_PERSONAL    66   \n\n                                            token_str  \\\n0                             jarviscindy@hotmail.com   \n1                             jarviscindy@hotmail.com   \n2                                               Jorge   \n3                                             Garrido   \n4                                           Alexandra   \n5                                               Beyer   \n6                                               María   \n7                                                José   \n8                                               Reyes   \n9                                                Kate   \n10                                             Daniel   \n11                                             Amparo   \n12                                           Pimienta   \n13                                             Amparo   \n14                                           Pimienta   \n15                                              Sipho   \n16                                           Mofokeng   \n17                                              Katja   \n18                                          Tschimmel   \n19                                          Tschimmel   \n20                                             Sascha   \n21                                             Gerber   \n22                                             Carlos   \n23                                          Hernandez   \n24                                             Melvin   \n25                                                 Lu   \n26  https://coursera.org/share/c353af95218bc2990ee...   \n27  https://coursera.org/share/c353af95218bc2990ee...   \n28                  https://www.facebook.com/pamela23   \n29                                             Brenda   \n30                                            Johnson   \n31                                             Brenda   \n32                                             Garcia   \n33                                              Robin   \n34                                              Duffy   \n35                                              Robin   \n36                                              Duffy   \n37                                             Blanca   \n38                                              Villa   \n39                                            Imtiyaz   \n40                                              Ritta   \n41                                           Isabella   \n42                                             Daniel   \n43                                                  Q   \n44                                          Schneider   \n45                                             Daniel   \n46                                             Daniel   \n47                                             Daniel   \n48                                             Daniel   \n49                                             Avitia   \n50                                              Edgar   \n51                                              Rojas   \n52                                            Jessica   \n53                                            Alvarez   \n54                                                 Md   \n55                                             Shamim   \n56                                              Cardo   \n57                                            Dalisay   \n58             https://hernandez.com/exploremain.html   \n59          https://www.roman.info/list/appindex.html   \n\n                                                 prob  \n0   [1.0, 2.2790219e-09, 1.546413e-09, 2.0085469e-...  \n1   [1.0, 2.148762e-09, 1.5796331e-09, 2.286665e-0...  \n2   [8.0853996e-10, 8.5100954e-10, 1.0, 2.0592634e...  \n3   [1.2815753e-09, 1.0856567e-09, 1.1890176e-09, ...  \n4   [7.0177797e-10, 7.6005435e-10, 1.0, 2.1657924e...  \n5   [1.1038538e-09, 1.0896252e-09, 1.8227403e-09, ...  \n6   [5.335832e-10, 7.658418e-10, 1.0, 2.0557904e-0...  \n7   [1.230865e-09, 1.2614872e-09, 1.4320612e-09, 1...  \n8   [1.1293931e-09, 1.3400011e-09, 1.3222492e-09, ...  \n9   [9.493654e-10, 8.978064e-10, 1.0, 2.1216033e-0...  \n10  [8.7950036e-10, 8.6661145e-10, 1.0, 2.2413125e...  \n11  [9.058152e-10, 9.2191604e-10, 1.0, 2.1487971e-...  \n12  [1.4143807e-09, 1.6061935e-09, 1.4414665e-09, ...  \n13  [8.393094e-10, 8.385217e-10, 1.0, 2.147952e-09...  \n14  [1.3647646e-09, 1.5614882e-09, 1.645121e-09, 1...  \n15  [7.4897766e-10, 8.6676466e-10, 1.0, 2.1945472e...  \n16  [1.2775949e-09, 1.3425394e-09, 1.1044735e-09, ...  \n17  [4.5364823e-10, 8.20357e-10, 0.5, 1.9445028e-0...  \n18  [3.274911e-07, 1.464391e-07, 1.5399255e-06, 2....  \n19  [9.592177e-10, 7.228172e-10, 2.3279363e-09, 1....  \n20  [7.306124e-10, 8.1845003e-10, 1.0, 2.1782331e-...  \n21  [1.1582596e-09, 1.0424122e-09, 1.2286132e-09, ...  \n22  [7.674898e-10, 8.0285556e-10, 1.0, 2.1876347e-...  \n23  [1.1380535e-09, 8.630321e-10, 1.4661335e-09, 1...  \n24  [7.787883e-10, 8.0790635e-10, 1.0, 1.8858517e-...  \n25  [1.4480965e-09, 1.2396082e-09, 1.4401499e-09, ...  \n26  [6.7895746e-07, 7.623262e-06, 1.8130487e-06, 3...  \n27  [4.738675e-07, 0.0005818847, 6.7490043e-07, 2....  \n28  [8.7870333e-10, 1.0088494e-09, 1.1190973e-09, ...  \n29  [6.3440153e-10, 7.424506e-10, 1.0, 2.2562296e-...  \n30  [1.1607807e-09, 8.566736e-10, 2.0160047e-09, 1...  \n31  [6.5329986e-10, 7.715746e-10, 1.0, 1.8186148e-...  \n32  [1.2377677e-09, 1.1013891e-09, 2.0962294e-09, ...  \n33  [7.9000906e-10, 8.0816376e-10, 1.0, 2.0424977e...  \n34  [1.1499213e-09, 1.1458489e-09, 1.3514282e-09, ...  \n35  [7.3151335e-10, 8.234365e-10, 1.0, 2.0034159e-...  \n36  [1.1953836e-09, 1.1627548e-09, 1.5504009e-09, ...  \n37  [7.4932205e-10, 7.6950524e-10, 1.0, 2.0439515e...  \n38  [1.3484208e-09, 1.1524002e-09, 1.3871915e-09, ...  \n39  [1.0462348e-09, 8.8225405e-10, 1.0, 2.3653317e...  \n40  [1.0235106e-09, 9.995683e-10, 1.0, 2.4874056e-...  \n41  [9.875367e-10, 8.70987e-10, 1.0, 2.0397133e-09...  \n42  [6.185413e-10, 1.3000351e-09, 1.0, 3.5498253e-...  \n43  [1.4301587e-09, 1.5322541e-09, 2.9516611e-09, ...  \n44  [9.2403696e-10, 1.6020194e-09, 2.7209202e-09, ...  \n45  [3.4209964e-09, 1.3951362e-08, 9.1637965e-05, ...  \n46  [2.4803386e-09, 5.799447e-09, 0.49999708, 1.30...  \n47  [6.5819767e-09, 1.945994e-08, 0.4999591, 3.922...  \n48  [1.6549706e-09, 1.9552162e-09, 0.9999999, 5.29...  \n49  [1.2276066e-06, 3.1563634e-06, 0.5492727, 9.13...  \n50  [7.973252e-10, 8.120328e-10, 1.0, 1.9015782e-0...  \n51  [1.2973376e-09, 1.2193125e-09, 1.5781003e-09, ...  \n52  [7.3525785e-10, 8.529368e-10, 1.0, 2.127101e-0...  \n53  [1.233916e-09, 1.1404394e-09, 1.7553781e-09, 1...  \n54  [7.592488e-10, 8.8929897e-10, 1.0, 2.2716626e-...  \n55  [1.2924244e-09, 1.1702834e-09, 1.5519133e-09, ...  \n56  [6.340443e-10, 7.967337e-10, 1.0, 2.2769648e-0...  \n57  [1.140775e-09, 1.1102474e-09, 1.0642984e-09, 1...  \n58  [6.951973e-10, 9.1845737e-10, 1.2314254e-09, 9...  \n59  [7.0143785e-10, 9.120656e-10, 1.1994856e-09, 9...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>label</th>\n      <th>token</th>\n      <th>token_str</th>\n      <th>prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11301</td>\n      <td>B-EMAIL</td>\n      <td>0</td>\n      <td>jarviscindy@hotmail.com</td>\n      <td>[1.0, 2.2790219e-09, 1.546413e-09, 2.0085469e-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11301</td>\n      <td>B-EMAIL</td>\n      <td>441</td>\n      <td>jarviscindy@hotmail.com</td>\n      <td>[1.0, 2.148762e-09, 1.5796331e-09, 2.286665e-0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3732</td>\n      <td>B-NAME_STUDENT</td>\n      <td>0</td>\n      <td>Jorge</td>\n      <td>[8.0853996e-10, 8.5100954e-10, 1.0, 2.0592634e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3732</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1</td>\n      <td>Garrido</td>\n      <td>[1.2815753e-09, 1.0856567e-09, 1.1890176e-09, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5470</td>\n      <td>B-NAME_STUDENT</td>\n      <td>10</td>\n      <td>Alexandra</td>\n      <td>[7.0177797e-10, 7.6005435e-10, 1.0, 2.1657924e...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5470</td>\n      <td>I-NAME_STUDENT</td>\n      <td>11</td>\n      <td>Beyer</td>\n      <td>[1.1038538e-09, 1.0896252e-09, 1.8227403e-09, ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>22088</td>\n      <td>B-NAME_STUDENT</td>\n      <td>17</td>\n      <td>María</td>\n      <td>[5.335832e-10, 7.658418e-10, 1.0, 2.0557904e-0...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22088</td>\n      <td>I-NAME_STUDENT</td>\n      <td>18</td>\n      <td>José</td>\n      <td>[1.230865e-09, 1.2614872e-09, 1.4320612e-09, 1...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>22088</td>\n      <td>I-NAME_STUDENT</td>\n      <td>19</td>\n      <td>Reyes</td>\n      <td>[1.1293931e-09, 1.3400011e-09, 1.3222492e-09, ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>12077</td>\n      <td>B-NAME_STUDENT</td>\n      <td>603</td>\n      <td>Kate</td>\n      <td>[9.493654e-10, 8.978064e-10, 1.0, 2.1216033e-0...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>12077</td>\n      <td>B-NAME_STUDENT</td>\n      <td>605</td>\n      <td>Daniel</td>\n      <td>[8.7950036e-10, 8.6661145e-10, 1.0, 2.2413125e...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>9473</td>\n      <td>B-NAME_STUDENT</td>\n      <td>0</td>\n      <td>Amparo</td>\n      <td>[9.058152e-10, 9.2191604e-10, 1.0, 2.1487971e-...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>9473</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1</td>\n      <td>Pimienta</td>\n      <td>[1.4143807e-09, 1.6061935e-09, 1.4414665e-09, ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>9473</td>\n      <td>B-NAME_STUDENT</td>\n      <td>519</td>\n      <td>Amparo</td>\n      <td>[8.393094e-10, 8.385217e-10, 1.0, 2.147952e-09...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>9473</td>\n      <td>I-NAME_STUDENT</td>\n      <td>520</td>\n      <td>Pimienta</td>\n      <td>[1.3647646e-09, 1.5614882e-09, 1.645121e-09, 1...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>8805</td>\n      <td>B-NAME_STUDENT</td>\n      <td>0</td>\n      <td>Sipho</td>\n      <td>[7.4897766e-10, 8.6676466e-10, 1.0, 2.1945472e...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>8805</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1</td>\n      <td>Mofokeng</td>\n      <td>[1.2775949e-09, 1.3425394e-09, 1.1044735e-09, ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>8805</td>\n      <td>B-NAME_STUDENT</td>\n      <td>404</td>\n      <td>Katja</td>\n      <td>[4.5364823e-10, 8.20357e-10, 0.5, 1.9445028e-0...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>8805</td>\n      <td>O</td>\n      <td>405</td>\n      <td>Tschimmel</td>\n      <td>[3.274911e-07, 1.464391e-07, 1.5399255e-06, 2....</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>8805</td>\n      <td>I-NAME_STUDENT</td>\n      <td>405</td>\n      <td>Tschimmel</td>\n      <td>[9.592177e-10, 7.228172e-10, 2.3279363e-09, 1....</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>11827</td>\n      <td>B-NAME_STUDENT</td>\n      <td>0</td>\n      <td>Sascha</td>\n      <td>[7.306124e-10, 8.1845003e-10, 1.0, 2.1782331e-...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>11827</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1</td>\n      <td>Gerber</td>\n      <td>[1.1582596e-09, 1.0424122e-09, 1.2286132e-09, ...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>6296</td>\n      <td>B-NAME_STUDENT</td>\n      <td>0</td>\n      <td>Carlos</td>\n      <td>[7.674898e-10, 8.0285556e-10, 1.0, 2.1876347e-...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>6296</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1</td>\n      <td>Hernandez</td>\n      <td>[1.1380535e-09, 8.630321e-10, 1.4661335e-09, 1...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2797</td>\n      <td>B-NAME_STUDENT</td>\n      <td>7</td>\n      <td>Melvin</td>\n      <td>[7.787883e-10, 8.0790635e-10, 1.0, 1.8858517e-...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2797</td>\n      <td>I-NAME_STUDENT</td>\n      <td>8</td>\n      <td>Lu</td>\n      <td>[1.4480965e-09, 1.2396082e-09, 1.4401499e-09, ...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>11049</td>\n      <td>O</td>\n      <td>138</td>\n      <td>https://coursera.org/share/c353af95218bc2990ee...</td>\n      <td>[6.7895746e-07, 7.623262e-06, 1.8130487e-06, 3...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>11049</td>\n      <td>B-URL_PERSONAL</td>\n      <td>138</td>\n      <td>https://coursera.org/share/c353af95218bc2990ee...</td>\n      <td>[4.738675e-07, 0.0005818847, 6.7490043e-07, 2....</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>11049</td>\n      <td>B-URL_PERSONAL</td>\n      <td>745</td>\n      <td>https://www.facebook.com/pamela23</td>\n      <td>[8.7870333e-10, 1.0088494e-09, 1.1190973e-09, ...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>9433</td>\n      <td>B-NAME_STUDENT</td>\n      <td>0</td>\n      <td>Brenda</td>\n      <td>[6.3440153e-10, 7.424506e-10, 1.0, 2.2562296e-...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>9433</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1</td>\n      <td>Johnson</td>\n      <td>[1.1607807e-09, 8.566736e-10, 2.0160047e-09, 1...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>9433</td>\n      <td>B-NAME_STUDENT</td>\n      <td>14</td>\n      <td>Brenda</td>\n      <td>[6.5329986e-10, 7.715746e-10, 1.0, 1.8186148e-...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>9433</td>\n      <td>I-NAME_STUDENT</td>\n      <td>15</td>\n      <td>Garcia</td>\n      <td>[1.2377677e-09, 1.1013891e-09, 2.0962294e-09, ...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>4004</td>\n      <td>B-NAME_STUDENT</td>\n      <td>0</td>\n      <td>Robin</td>\n      <td>[7.9000906e-10, 8.0816376e-10, 1.0, 2.0424977e...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>4004</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1</td>\n      <td>Duffy</td>\n      <td>[1.1499213e-09, 1.1458489e-09, 1.3514282e-09, ...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>4004</td>\n      <td>B-NAME_STUDENT</td>\n      <td>479</td>\n      <td>Robin</td>\n      <td>[7.3151335e-10, 8.234365e-10, 1.0, 2.0034159e-...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>4004</td>\n      <td>I-NAME_STUDENT</td>\n      <td>480</td>\n      <td>Duffy</td>\n      <td>[1.1953836e-09, 1.1627548e-09, 1.5504009e-09, ...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>3664</td>\n      <td>B-NAME_STUDENT</td>\n      <td>10</td>\n      <td>Blanca</td>\n      <td>[7.4932205e-10, 7.6950524e-10, 1.0, 2.0439515e...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>3664</td>\n      <td>I-NAME_STUDENT</td>\n      <td>11</td>\n      <td>Villa</td>\n      <td>[1.3484208e-09, 1.1524002e-09, 1.3871915e-09, ...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>1763</td>\n      <td>B-NAME_STUDENT</td>\n      <td>13</td>\n      <td>Imtiyaz</td>\n      <td>[1.0462348e-09, 8.8225405e-10, 1.0, 2.3653317e...</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>14695</td>\n      <td>B-NAME_STUDENT</td>\n      <td>205</td>\n      <td>Ritta</td>\n      <td>[1.0235106e-09, 9.995683e-10, 1.0, 2.4874056e-...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>14695</td>\n      <td>B-NAME_STUDENT</td>\n      <td>207</td>\n      <td>Isabella</td>\n      <td>[9.875367e-10, 8.70987e-10, 1.0, 2.0397133e-09...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>9657</td>\n      <td>B-NAME_STUDENT</td>\n      <td>241</td>\n      <td>Daniel</td>\n      <td>[6.185413e-10, 1.3000351e-09, 1.0, 3.5498253e-...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>9657</td>\n      <td>I-NAME_STUDENT</td>\n      <td>242</td>\n      <td>Q</td>\n      <td>[1.4301587e-09, 1.5322541e-09, 2.9516611e-09, ...</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>9657</td>\n      <td>I-NAME_STUDENT</td>\n      <td>243</td>\n      <td>Schneider</td>\n      <td>[9.2403696e-10, 1.6020194e-09, 2.7209202e-09, ...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>9657</td>\n      <td>O</td>\n      <td>283</td>\n      <td>Daniel</td>\n      <td>[3.4209964e-09, 1.3951362e-08, 9.1637965e-05, ...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>9657</td>\n      <td>O</td>\n      <td>888</td>\n      <td>Daniel</td>\n      <td>[2.4803386e-09, 5.799447e-09, 0.49999708, 1.30...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>9657</td>\n      <td>O</td>\n      <td>952</td>\n      <td>Daniel</td>\n      <td>[6.5819767e-09, 1.945994e-08, 0.4999591, 3.922...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>9657</td>\n      <td>B-NAME_STUDENT</td>\n      <td>1402</td>\n      <td>Daniel</td>\n      <td>[1.6549706e-09, 1.9552162e-09, 0.9999999, 5.29...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>12426</td>\n      <td>B-NAME_STUDENT</td>\n      <td>169</td>\n      <td>Avitia</td>\n      <td>[1.2276066e-06, 3.1563634e-06, 0.5492727, 9.13...</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>4442</td>\n      <td>B-NAME_STUDENT</td>\n      <td>6</td>\n      <td>Edgar</td>\n      <td>[7.973252e-10, 8.120328e-10, 1.0, 1.9015782e-0...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>4442</td>\n      <td>I-NAME_STUDENT</td>\n      <td>7</td>\n      <td>Rojas</td>\n      <td>[1.2973376e-09, 1.2193125e-09, 1.5781003e-09, ...</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>14191</td>\n      <td>B-NAME_STUDENT</td>\n      <td>1392</td>\n      <td>Jessica</td>\n      <td>[7.3525785e-10, 8.529368e-10, 1.0, 2.127101e-0...</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>14191</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1393</td>\n      <td>Alvarez</td>\n      <td>[1.233916e-09, 1.1404394e-09, 1.7553781e-09, 1...</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>4669</td>\n      <td>B-NAME_STUDENT</td>\n      <td>13</td>\n      <td>Md</td>\n      <td>[7.592488e-10, 8.8929897e-10, 1.0, 2.2716626e-...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>4669</td>\n      <td>I-NAME_STUDENT</td>\n      <td>14</td>\n      <td>Shamim</td>\n      <td>[1.2924244e-09, 1.1702834e-09, 1.5519133e-09, ...</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>10472</td>\n      <td>B-NAME_STUDENT</td>\n      <td>0</td>\n      <td>Cardo</td>\n      <td>[6.340443e-10, 7.967337e-10, 1.0, 2.2769648e-0...</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>10472</td>\n      <td>I-NAME_STUDENT</td>\n      <td>1</td>\n      <td>Dalisay</td>\n      <td>[1.140775e-09, 1.1102474e-09, 1.0642984e-09, 1...</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>13103</td>\n      <td>B-URL_PERSONAL</td>\n      <td>63</td>\n      <td>https://hernandez.com/exploremain.html</td>\n      <td>[6.951973e-10, 9.1845737e-10, 1.2314254e-09, 9...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>13103</td>\n      <td>B-URL_PERSONAL</td>\n      <td>66</td>\n      <td>https://www.roman.info/list/appindex.html</td>\n      <td>[7.0143785e-10, 9.120656e-10, 1.1994856e-09, 9...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# the original train dataset does not have a column that associates the provided token to a number so here we add it\ndef add_token_id(row):\n    row['token'] = np.arange(len(row['tokens']))\n    return row\nds_original_w_labels = ds_original_w_labels.map(add_token_id, num_proc = 4)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:02:19.602685Z","iopub.execute_input":"2024-03-13T10:02:19.603088Z","iopub.status.idle":"2024-03-13T10:02:24.750609Z","shell.execute_reply.started":"2024-03-13T10:02:19.603057Z","shell.execute_reply":"2024-03-13T10:02:24.749614Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/341 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e83893d8afb4ae2871bff9d6b5d6371"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/341 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f495f41a9eed48089a647b2d9fe071b5"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/340 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2d1f3ac78c64431acc884b64b747e16"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/340 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888e5d8c139d46ec9b1760df0cb1bc9e"}},"metadata":{}}]},{"cell_type":"code","source":"ds_original_w_labels.set_format('pandas')\nds_original_w_labels = ds_original_w_labels[:]\nds_original_w_labels = ds_original_w_labels.explode(['provided_labels', 'token'])\nall_positives = ds_original_w_labels[ds_original_w_labels['provided_labels'] != 'O']\nall_positives = all_positives.rename(columns = {'provided_labels': 'label'})","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:02:28.175126Z","iopub.execute_input":"2024-03-13T10:02:28.175508Z","iopub.status.idle":"2024-03-13T10:02:28.751311Z","shell.execute_reply.started":"2024-03-13T10:02:28.175474Z","shell.execute_reply":"2024-03-13T10:02:28.750353Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"total_predictions_df = all_documents_predictions_df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:02:30.401734Z","iopub.execute_input":"2024-03-13T10:02:30.402099Z","iopub.status.idle":"2024-03-13T10:02:30.408914Z","shell.execute_reply.started":"2024-03-13T10:02:30.402071Z","shell.execute_reply":"2024-03-13T10:02:30.407897Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def assess_performance_threshold(all_documents_predictions_df, threshold):\n\n    matrix_probs = np.array([np.array(row) for row in all_documents_predictions_df['prob']])\n    preds_normal = np.argmax(matrix_probs,axis = -1)\n    preds_without_O = np.argmax(matrix_probs[:,:12],axis = -1)\n    O_preds = matrix_probs[:,-1]\n    labels = np.where(O_preds < threshold, preds_without_O , preds_normal)\n    labels = np.array([id2label[str(label)] for label in labels])\n    all_documents_predictions_df['label'] = labels\n    all_documents_predictions_df = all_documents_predictions_df.drop(columns = ['prob'])\n    all_documents_predictions_df = all_documents_predictions_df[all_documents_predictions_df['label'] != 'O']\n    all_documents_predictions_df = all_documents_predictions_df.reset_index()\n    all_documents_predictions_df = all_documents_predictions_df.drop(columns = ['index'])\n    all_documents_predictions_df['row_id'] = all_documents_predictions_df.index\n    true_positives = pd.merge(all_documents_predictions_df, all_positives, on=['document', 'label', 'token'])\n    precision = len(true_positives)/ len(all_documents_predictions_df)\n    recall = len(true_positives)/ len(all_positives)\n    f5 = (1+25)*(precision*recall/(25*precision + recall))\n    return f5","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:02:32.337203Z","iopub.execute_input":"2024-03-13T10:02:32.337926Z","iopub.status.idle":"2024-03-13T10:02:32.349415Z","shell.execute_reply.started":"2024-03-13T10:02:32.337881Z","shell.execute_reply":"2024-03-13T10:02:32.348502Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"thresholds = 1-np.logspace(-6, -1, num=1000) \nf5_scores = []\nfor threshold in thresholds:\n    f5_scores.append(assess_performance_threshold(total_predictions_df, threshold))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:07:07.805672Z","iopub.execute_input":"2024-03-13T10:07:07.806021Z","iopub.status.idle":"2024-03-13T10:07:16.303369Z","shell.execute_reply.started":"2024-03-13T10:07:07.805993Z","shell.execute_reply":"2024-03-13T10:07:16.302395Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"idx = np.argmax(np.array(f5_scores))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:07:22.916662Z","iopub.execute_input":"2024-03-13T10:07:22.917419Z","iopub.status.idle":"2024-03-13T10:07:22.922219Z","shell.execute_reply.started":"2024-03-13T10:07:22.917385Z","shell.execute_reply":"2024-03-13T10:07:22.921052Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"thresholds[idx]","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:08:15.908596Z","iopub.execute_input":"2024-03-13T10:08:15.908975Z","iopub.status.idle":"2024-03-13T10:08:15.914850Z","shell.execute_reply.started":"2024-03-13T10:08:15.908947Z","shell.execute_reply":"2024-03-13T10:08:15.914000Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"0.9999073240669886"},"metadata":{}}]},{"cell_type":"code","source":"f5_scores[idx]","metadata":{"execution":{"iopub.status.busy":"2024-03-13T10:08:06.606794Z","iopub.execute_input":"2024-03-13T10:08:06.607155Z","iopub.status.idle":"2024-03-13T10:08:06.613275Z","shell.execute_reply.started":"2024-03-13T10:08:06.607126Z","shell.execute_reply":"2024-03-13T10:08:06.612381Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"0.9694511676587949"},"metadata":{}}]}]}